func (tk *Tokenizer) Clean(tokens []*Token) []*Token {
	ret := make([]*Token, 0)
	var last *Token
	for _, tok := range tokens {
		if tok.Kind == TokenTypeNewline {
			if last != nil && last.Kind != TokenTypeOpSemi {
				insertSemi := false
				switch last.Kind {
				// ident, number, string, ), ], }, ++, --, fallthrough, break, return, continue
				case TokenTypeIdent, TokenTypeString, TokenTypeOpRightParen, TokenTypeOpRightBracket,
				    TokenTypeOpRightBrace, TokenTypeOpPlusPlus, TokenTypeOpMinusMinus, TokenTypeNumber:
					last = NewToken(TokenTypeOpSemi, last.Start, last.End, []rune(";"))
					ret = append(ret, last)
				}
			}
		}
		if tok.Kind == TokenTypeWhitespace || tok.Kind == TokenTypeNewline || tok.Kind == TokenTypeComment {
			continue
		}
		ret = append(ret, tok)
		last = tok
		if tok.Kind == TokenTypeEndOfFile {
			break
		}
	}
	return ret
}

func (ps *Parser) _enter() {
	ps._any = ps._bracketDepth + 1
}

func (ps *Parser) _leave() {
	ps.any = 0
}

func (ps *Parser) _hackCompositeLitNode() Node {
	if ps._bracketDepth >= ps._any.(int) {
		return ps.compositeLit()
	}
	return nil
}